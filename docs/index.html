<!DOCTYPE html>
<html>
<head>
<title>Fractional Polynomial Noise</title>
<link rel="stylesheet" type="text/css" href="index.css">
</head>
<body>
<h1>Fractional Polynomial Noise</h1>
<p>
Copyright &copy; 2021 Ruud Helderman
&lt;<a href="mailto:r.helderman@hccnet.nl">r.helderman@hccnet.nl</a>&gt;
</p>
<p>
<a href="../LICENSE">MIT licensed</a>
</p>
<h2>Purpose</h2>
<p>
Experimental algorithm for
<a href="https://en.wikipedia.org/wiki/Gradient_noise">gradient noise</a>.
I am using this for real-time
<a href="https://en.wikipedia.org/wiki/Procedural_generation">procedural generation</a>
of (practically) infinite landscapes in animations and video games.
I could have implemented an existing algorithm like
<a href="https://en.wikipedia.org/wiki/Perlin_noise">Perlin noise</a> or
<a href="https://en.wikipedia.org/wiki/Simplex_noise">Simplex noise</a>,
but I found the complexity in those algorithms alarming.
I am looking for noise, not the Mona Lisa.
</p>
<p>
After many failed experiments, I found something that looked really good.
It has many similarities with
<a href="https://en.wikipedia.org/wiki/Perlin_noise">Perlin noise</a>,
but it is simpler,
and it appears to be inherently free from directional artifacts.
</p>
<h2>Example</h2>
<p>
Click the image to see it in full size.
</p>
<p>
<a href="noise2D.png"><img src="noise2D.png" alt="Demo of Fractional Polynomial Noise" style="width:25%" /></a>
</p>
<p>
The image is the result of the following formula:
</p>
<div class="formula">
<i>h</i>(<i>x</i>, <i>y</i>) =
<div class="sum">
	<div>&lfloor;<i>x</i>&rfloor; + 2</div>
	<div class="sigma">&Sigma;</div>
	<div><i>i</i> = &lfloor;<i>x</i>&rfloor; &minus; 1</div>
</div>
&nbsp;
<div class="sum">
	<div>&lfloor;<i>y</i>&rfloor; + 2</div>
	<div class="sigma">&Sigma;</div>
	<div><i>j</i> = &lfloor;<i>y</i>&rfloor; &minus; 1</div>
</div>
<span class="par2">(</span>
<i>p</i><sub>1</sub>(<i>i</i>, <i>j</i>) (<i>x</i> &minus; <i>i</i>) +
<i>p</i><sub>2</sub>(<i>i</i>, <i>j</i>) (<i>y</i> &minus; <i>j</i>) +
<i>p</i><sub>3</sub>(<i>i</i>, <i>j</i>)
<span class="par2">)</span>
<span class="par2">(</span>1 &minus;
<span class="par1">(</span>
<table>
	<tr><td><i>x</i> &minus; <i>i</i></td></tr>
	<tr><td class="denominator">2</td></tr>
</table>
<span class="par1">)<sup>2</sup></span>
<span class="par2">)<sup><i>n</i></sup></span>
<span class="par2">(</span>1 &minus;
<span class="par1">(</span>
<table>
	<tr><td><i>y</i> &minus; <i>j</i></td></tr>
	<tr><td class="denominator">2</td></tr>
</table>
<span class="par1">)<sup>2</sup></span>
<span class="par2">)<sup><i>n</i></sup></span>
</div>
<p>
where <i>n</i> = 4.67970975809363 (far from obvious; explained below)
and <i>p</i><sub>1</sub>, <i>p</i><sub>2</sub>, <i>p</i><sub>3</sub>
are hash functions generating pseudo-random numbers in the range (&minus;1, 1).
These can be three different functions,
or (more likely) the same function with 3 different salts.
</p>
<h2>Explanation</h2>
<p>
We start off really simple: a one-dimensional curve, defined by a
<a href="https://en.wikipedia.org/wiki/Piecewise">piecewise function</a>.
There is an infinite number of subdomains, all of which have the same length.
Every endpoint (where two subdomains meet) has a pseudo-random height.
It is straightforward to connect the dots with straight lines.
The result is a 'curve' with G0 continuity:
the function is continous (there are no 'jumps'),
but steepness (the function's
<a href="https://en.wikipedia.org/wiki/Derivative">derivative</a>)
is <i>not</i> continuous, making the line jaggy.
</p>
<p>
The next step is obvious:
we give every endpoint a pseudo-random steepness,
and obey that steepness as we connect endpoints.
This is easy enough with third-degree
<a href="https://en.wikipedia.org/wiki/Polynomial">polynomials</a>.
The resulting curve has G1 continuity:
both the height function and its first derivative are continuous,
but the second derivative is not.
</p>
<p>
We can make the curve even smoother by aiming for G2 continuity.
Again, this is not too hard:
we add yet another psuedo-random number to every endpoint,
this time representing the desired value for the <i>second</i> derivative,
and we use a fifth-degree polynomial to connect the endpoints.
</p>
<p>
All this is nothing new:
Perlin noise was already using third-degree polynomials,
and later fifth-degree polynomials,
in the way it interpolated between gradients
(<a href="https://en.wikipedia.org/wiki/Smoothstep">smoothstep</a>).
But it was at this point that I was wondering:
is it really necessary to involve so many pseudo-random numbers
in the calculation of a single subfunction?
Four for G1 continuity, six for G2, and so on.
Please note, I am not worried about the performance of these calculations.
I am just concerned about the complexity of any such formula.
I like to keep things as simple as possible.
</p>
<p>
Let's try something else:
polynomials that are always zero at their endpoints.
Zero height, zero derivative,
and depending on our demands, one or more higher derivatives that are zero.
The random factor will be in the <i>center</i> of the domain:
there we will pseudo-randomly choose a height and a steepness.
Nothing more.
That way, only two pseudo-random numbers are needed to calculate a subfunction.
And those numbers belong to a single subdomain,
rather than being shared between two neighboring subdomains.
Nice and simple.
</p>
<p>
For example, let's say we want G1 continuity.
Imagine for subdomain (&minus;1, 1), we have picked two pseudo-random numbers:
<i>a</i> for the steepness and <i>b</i> for the height
at the center of the subdomain (<i>x</i> = 0).
In other words, the curve has a
<a href="https://en.wikipedia.org/wiki/Tangent">tangent</a>
<i>y</i> = <i>a</i><i>x</i> + <i>b</i>.
We need to find a subfunction <i>f</i> that satisfies the following conditions:
</p>
<ul>
	<li><i>f</i> (0) = <i>b</i></li>
	<li><i>f '</i> (0) = <i>a</i></li>
	<li><i>f</i> (1) = <i>f</i> (&minus;1) = 0</li>
	<li><i>f '</i> (1) = <i>f '</i> (&minus;1) = 0</li>
</ul>
<p>
The following third-degree polynomial does just that:
</p>
<div class="formula">
<i>f</i> (<i>x</i>) =
(<i>a x</i> + <i>b</i>) (1 &minus; <i>x</i><sup>2</sup>)
</div>
<p>
Yes, I am aware there will be a 'valley' at every endpoint.
We will try to compensate by using overlapping subdomains
(using the sum of the overlapping subfunctions as the height).
One would expect: the more overlap, the better the valleys will be filled up.
But too much overlap is computationally expensive
and may make the landscape bland, due to prominent peaks being averaged out.
</p>
<p>
The easiest way to see the effect of overlap is to use constant coefficients across the entire landscape, rather than pseudo-random numbers.
With <i>a</i> = 0 and <i>b</i> = 2, we see identical 'hills',
with no distractions coming from 'random' variations:
</p>
<p>
An overlap of 50% seems insufficient to fill the holes:
</p>
<p>
75% looks a lot better:
</p>
<p>
This basically means every piece of land is covered by 4 polynomials.
Of course, this immediately eliminates the advantage of
having to calculate fewer random numbers (especially in higher dimensions),
but like I said earlier, right now I'm more worried about complexity.
And overlaps are not complex.
</p>
<p>
Let's see if we can improve our polynomial.
To achieve G2 continuity,
we need the following condition in addition to the ones listed earlier:
</p>
<ul>
	<li><i>f ''</i> (1) = <i>f ''</i> (&minus;1) = 0</li>
</ul>
<p>
This time we need a fifth-degree polynomial to satisfy all conditions:
</p>
<div class="formula">
<i>f</i> (<i>x</i>) =
(<i>a x</i> + <i>b</i>) (1 &minus; <i>x</i><sup>2</sup>)<sup>2</sup>
</div>
<p>
Notice this looks <i>very</i> similar to our previous polynomial.
It isn't hard to guess how to generalize this for higher levels of continuity:
</p>
<div class="formula">
<i>f</i> (<i>x</i>) =
(<i>a x</i> + <i>b</i>) (1 &minus; <i>x</i><sup>2</sup>)<sup><i>n</i></sup>
</div>
<p>
This basically means we can increase smoothness as much as we like.
But that does not necessarily make the curve better.
In fact, at higher values of <i>n</i>, it becomes worse.
Look what happens with the overlapping polynomials as we increase <i>n</i>:
</p>
<p>
This is because the increasing demand on smoothness at the endpoints,
makes the 'valleys' around the endpoints wider, and the hills narrower.
In general, the flatter the plot,
the lesser the chance of seeing directional artifacts like grid lines in 2D.
It appears 3, 4 and 5 are good values for <i>n</i>.
But where is the optimum? It has to be somewhere between 4 and 5.
Well, what's keeping us from using a non-integer <i>n</i>?
(1 &minus; <i>x</i><sup>2</sup>) is always positive
within the subdomain (&minus;1, 1),
so there is no problem in having a fractional exponent.
</p>
<p>
With some experimenting, it's easy to find the optimum is around 4.68:
</p>
<p>
For a more accurate number, let's assume (I haven't proven this)
the optimum is the point where the two extremes of overlap
have the same height:
</p>
<ul>
<li>where endpoint and center overlap, e.g. <i>x</i> = 0</li>
<li>halfway between two points as described above, e.g. <i>x</i> = 0.25</li>
</ul>
<p>
This results in the following equation:
</p>
<div class="formula">
<table>
	<tr><td>1</td></tr>
	<tr><td class="denominator">2</td></tr>
</table>
+
<span class="par1">(</span>
<table>
	<tr><td>3</td></tr>
	<tr><td class="denominator">4</td></tr>
</table>
<span class="par1">)<sup><i>n</i></sup></span>
=
<span class="par1">(</span>
<table>
	<tr><td>7</td></tr>
	<tr><td class="denominator">16</td></tr>
</table>
<span class="par1">)<sup><i>n</i></sup></span>
+
<span class="par1">(</span>
<table>
	<tr><td>15</td></tr>
	<tr><td class="denominator">16</td></tr>
</table>
<span class="par1">)<sup><i>n</i></sup></span>
</div>
<p>
One of the roots of this equation is 4.67970975809363 (approximately),
an excellent match for what we already observed.
</p>
<h2>1D</h2>
<p>
After scaling <i>x</i> so that subdomains are at unit-length distances,
we come to this formula:
</p>
<div class="formula">
<i>h</i>(<i>x</i>) =
<div class="sum">
	<div>&lfloor;<i>x</i>&rfloor; + 2</div>
	<div class="sigma">&Sigma;</div>
	<div><i>i</i> = &lfloor;<i>x</i>&rfloor; &minus; 1</div>
</div>
<span class="par2">(</span>
<i>p</i><sub>1</sub>(<i>i</i>) (<i>x</i> &minus; <i>i</i>) +
<i>p</i><sub>2</sub>(<i>i</i>)
<span class="par2">)</span>
<span class="par2">(</span>1 &minus;
<span class="par1">(</span>
<table>
	<tr><td><i>x</i> &minus; <i>i</i></td></tr>
	<tr><td class="denominator">2</td></tr>
</table>
<span class="par1">)<sup>2</sup></span>
<span class="par2">)<sup><i>n</i></sup></span>
</div>
<p>
Notice the &Sigma; operator always sums 4 terms,
meaning subsequent subdomains overlap for 75%.
The number of hash calculations is 8 per unit-length.
</p>
<h2>2D</h2>
<p>
We already saw this formula at the start of this document:
</p>
<div class="formula">
<i>h</i>(<i>x</i>, <i>y</i>) =
<div class="sum">
	<div>&lfloor;<i>x</i>&rfloor; + 2</div>
	<div class="sigma">&Sigma;</div>
	<div><i>i</i> = &lfloor;<i>x</i>&rfloor; &minus; 1</div>
</div>
&nbsp;
<div class="sum">
	<div>&lfloor;<i>y</i>&rfloor; + 2</div>
	<div class="sigma">&Sigma;</div>
	<div><i>j</i> = &lfloor;<i>y</i>&rfloor; &minus; 1</div>
</div>
<span class="par2">(</span>
<i>p</i><sub>1</sub>(<i>i</i>, <i>j</i>) (<i>x</i> &minus; <i>i</i>) +
<i>p</i><sub>2</sub>(<i>i</i>, <i>j</i>) (<i>y</i> &minus; <i>j</i>) +
<i>p</i><sub>3</sub>(<i>i</i>, <i>j</i>)
<span class="par2">)</span>
<span class="par2">(</span>1 &minus;
<span class="par1">(</span>
<table>
	<tr><td><i>x</i> &minus; <i>i</i></td></tr>
	<tr><td class="denominator">2</td></tr>
</table>
<span class="par1">)<sup>2</sup></span>
<span class="par2">)<sup><i>n</i></sup></span>
<span class="par2">(</span>1 &minus;
<span class="par1">(</span>
<table>
	<tr><td><i>y</i> &minus; <i>j</i></td></tr>
	<tr><td class="denominator">2</td></tr>
</table>
<span class="par1">)<sup>2</sup></span>
<span class="par2">)<sup><i>n</i></sup></span>
</div>
<p>
Overlap is 4 &times; 4 = 16.
The number of hash calculations per unit square is 3 &times; 16 = 48.
</p>
<h2>Higher dimensions</h2>
<p>
Extending the formula to higher dimensions is straightforward,
but the number of hash calculations grows exponentially with the dimension.
<a href="https://en.wikipedia.org/wiki/Perlin_noise">Perlin noise</a>
has a similar issue.
You may be better off with
<a href="https://en.wikipedia.org/wiki/Simplex_noise">Simplex noise</a> or
<a href="https://en.wikipedia.org/wiki/OpenSimplex_noise">OpenSimplex noise</a>.
</p>
<h2>Disclaimer</h2>
<p>
I am not a mathematician,
I am a software engineer with just enough knowledge and experience
to understand some of the challenges in this area.
I am open for criticism; please let me know if I missed something.
</p>
</body>
</html>
